{
  "hash": "603a15f279a8c797cdd4dda493112cb0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: CNN\nengine: knitr\n---\n\n\n\n\n\n\n이번에는 텍스트 생성 프로젝트를 수행합니다.\n\nText-to-text Generation은, input과 output이 모두 텍스트(text)인 작업을 말합니다.\n\n현재 Transformer에서 제공하는 언어 모델(Language Model) 중 가장 작은 모델인 GPT-2를 활용하여 진행해보겠습니다.\n\n진행에 앞서, Transformer 라이브러리를 간단히 확인하고 넘어가겠습니다.\n\n</br>\n🤖 Transformer\n\n먼저 Transformer는 2017년 구글 논문 \"Attention Is All You Need\"에서 처음 소개된 딥러닝 모델입니다.\n주로 자연어 처리(NLP)에 사용되며, 기존의 RNN, LSTM보다 훨씬 강력하고 효율적인 모델이라고 할 수 있습니다.\n\nTransformers 라이브러리는 Hugging Face에서 만든 자연어 처리(NLP) 및 인공지능 모델 라이브러리입니다.\n라이브러리를 사용하면 복잡한 딥러닝 기반 AI 모델(예: BERT, GPT, T5 등)을 쉽게 불러와 사용할 수 있습니다.\n</br>\n</br>\n\n### 1. 배치 파일 생성 {.unnumbered}\n\n프로젝트 수행을 위한 배치 파일을 생성합니다.\n\n아래의 사항을 본인의 작업(job)에 맞게 입력한 후, 본인이 원하는 파일의 이름을 지정하여 `filename.sh` 형식으로 파일을 저장합니다.\n예를 들어, 아래의 Shell 파일을 `t2t.sh`로 저장해보겠습니다.\n\n파일명이 `.sh` 형식인지 반드시 확인하세요.\n\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n#!/bin/bash\n#SBATCH --job-name=t2t_g\n#SBATCH --output=./output/t2t_%n_%j.out\n#SBATCH --error=./output/t2t_%n_%j.err\n#SBATCH --nodes=1\n#SBATCH --partition=gpu4\n#SBATCH --gres=gpu:4\n#SBATCH --cpus-per-task=16\n#SBATCH --mem=128G\n#SBATCH --time=24:00:00\n\necho \"start at:\" `date` # 접속한 날짜 표기\necho \"node: $HOSTNAME\" # 접속한 노드 번호 표기\necho \"jobid: $SLURM_JOB_ID\" # jobid 표기\n\n# Load modules (cuda 환경)\nmodule load cuda/11.8 # \n\n# Load env (python 환경)\nsource ~/miniconda3/bin/activate ubai\npip install --upgrade pip  # pip 최신 버전 유지\npip install -r requirements.txt # 필요 라이브러리 설치\n\n# 스크립트 실행\npython t2t.py\n```\n:::\n\n\n\n\n\n\n결과값 도출 지정 폴더 이름을 반드시 지정해주세요. 각각 결과 값 폴더를 따로따로 만들어주거나 아니면 동일 폴더에 지정하셔도 됩니다.\n\nSTDOUT은 결과 값 출력 파일, STDERR는 결과 값 도출 중 출력 되는 로그 파일입니다. 새 폴더를 만들기 위해서는 디렉토리(directory)에서 오른쪽 버튼을 눌러 새 폴더 만들기 버튼을 클릭하시면 됩니다.\n\n각 라인들의 의미는 다음과 같습니다.\n\n✔ **`#SBATCH --nodes=1`** \n\n- 총 필요 노드 수를 지정하는 명령어이며, 노드는 자동으로 컴퓨터가 배정해줍니다.\n- nodes=1은 노드를 한 개만 사용하겠다는 의미입니다.\n\n\n✔ **`#SBATCH --partition=gpu4`** \n\n- 사용할 Partition을 지정하는 명령어입니다.\n\n\n✔ **`#SBATCH --cpus-per-task=14`** \n\n- 총 필요 코어의 개수를 지정하는 명령어입니다.\n- 노드는 n개의 코어를 가지며, 사용 노드 1개 당 몇 개의 CPU/GPU 코어를 쓸 것인지를 결정합니다.\n\n\n✔ **`#SBATCH --gres=gpu:1`** \n\n- 몇 개의 GPU를 사용할 것인지 지정하는 명령어입니다.\n- CPU Partition을 선택하신 경우 해당 코드는 지워주셔야 합니다. 해당 코드는 GPU의 개수를 지정하는 명령어이기에, 에러가 발생할 수 있습니다.\n\n\n✔ **`#SBATCH --job-name=UBAIJOB`** \n\n- 작업 이름을 지정하는 명령어입니다.\n\n\n✔ **`echo \"start at:\" 'date'`** \n\n- 접속 날짜가 표기됩니다.\n\n\n✔ **`echo \"node: $HOSTNAME\"`** \n\n- 접속한 노드 번호가 표기됩니다.\n\n\n✔ **`echo \"jobid: $SLURM_JOB_ID\"`** \n\n- jobid가 표기됩니다.\n\n\n✔ **`module ~`** \n\n- 원하는 Linux 환경을 구축할 수 있습니다.\n- 기본적으로 CUDA/11.2.2 실행으로 셋팅되어 있습니다. 지금과 같이 다른 GPU 환경을 원할 경우, 해당 모듈을 unload한 후, 원하는 모듈을 load 합니다.\n- GPU 환경을 사용하고 싶은 경우에만 해당하며, GPU 환경을 사용하지 않을 경우(CPU Partition 사용) 지우셔도 무관합니다.\n\n✔ **`source ~/miniconda3/bin/activate ubai`** \n\n- ubai라는 python 가상환경을 실행시킵니다.\n   - ubai는 임의로 작성한 가상환경으로, 본인이 생성한 가상환경의 이름을 입력하셔야 합니다.\n- 이 때, activate하는 위치는 본인이 다운로드 받은 conda 경로로 설정되어야 합니다.\n\n✔ **`pip install -r requirements.txt`** \n\n- 실행시키고자하는 python 가상환경에, 필요한 라이브러리를 자동으로 다운받습니다.\n- conda 가상환경을 만든 후, 사전에 필요 라이브러리를 모두 설치해두었다면, 별도로 작성할 필요가 없습니다.\n\n✔ **`python t2t.py`** \n\n- 원하는 Python 파일을 실행합니다.\n- 실행하려는 파일은 반드시 `.py`파일의 형태로 존재해야합니다.\n\n\n</br>\n\n### 2. 배치 파일 실행 {.unnumbered}\n\n배치 파일을 실행하기에 앞서, 본인이 생성했던 Python 가상 환경에 들어와 있는 상태인지 재 확인합니다.\n\n이후, terminal에 `sbatch` 명령어를 이용하여 지정한 배치 파일명을 입력 및 실행하세요. 이는 작업(job)을 제출한다는 의미입니다.\n\n실행 후 나온 결과 값은 작업(job)에 대한 ID이니 꼭 따로 저장하거나 메모해두시기를 요청드립니다.\n\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsbatch t2t.sh    # sbatch filename.sh \n```\n:::\n\n\n\n\n\n\n</br>\n\n작업(job) 제출이 정상적으로 진행되었다면, STDOUT폴더 안에 OUT 파일이 생성됩니다.\n\n만일 OUT파일이 생성되지 않았다면, 해당 Partition의 노드에 기존 작업(job)이 모두 할당되어 수행하지 못했을 가능성이 높습니다.\n이 경우 terminal에 `squeue` 명령어를 입력하시고, 본인의 ID를 찾습니다.\n\n보통 배정이 되어있다면 정상적으로 n001, n002 … 으로 노드에 배정되어 있지만, 배정되지 않았을 경우 ( *Resources, Priority* )라는 메시지를 볼 수 있습니다. 그런 경우 다른 노드가 일이 끝나는 것을 기다리거나, 해당 파티션이 아닌 다른 파티션을 이용하여 노드를 배정받아야 합니다.\n\n다른 파티션을 이용하기 위해서는 Partition 목록에서 Partition과 cpus-per-task, gpu 갯수를 Partition에 맞게 수정하여 작업(job)을 다시 제출하셔야 합니다.\n\n</br>\n\n이제 STDOUT폴더에 생성된 실행 결과 OUT파일을 확인할 수 있습니다.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}